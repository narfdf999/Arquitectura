{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Autoencoder.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/narfdf999/Arquitectura/blob/master/Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAgDrB90Vw_n",
        "colab_type": "code",
        "outputId": "bd702d3a-013a-404f-dbca-cefb5f08b8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M_ZTNwIrLiD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, BatchNormalization, Reshape, Conv2DTranspose\n",
        "from keras.models import Model ,Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras import backend as K\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK9Cxgih7R_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load Dataset\n",
        "def load_data():\n",
        "  path = '/content/drive/My Drive/1260_mercator'\n",
        "  x_train = np.load('/content/drive/My Drive/1260_mercator/01a.npy')\n",
        "\n",
        "  for filename in glob.glob(os.path.join(path, '*.npy')):\n",
        "    if(filename != '/content/drive/My Drive/1260_mercator/01a.npy'):\n",
        "      print(filename)\n",
        "      aux=np.load(filename)\n",
        "      print(x_train.shape)\n",
        "      print(aux.shape)\n",
        "      x_train=np.concatenate((x_train,aux),axis = 0)  \n",
        "\n",
        "  return x_train\n",
        "\n",
        "x_train = load_data()\n",
        "print(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sflG0STWcq6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/1260_mercator/mercator_total.npy',x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFVLioYX70Nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Noise to our MNNIST Dataset by sampling random values from Gaussian distribution by using np.random.normal() and adding it to our original images to change pixel values\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)\n",
        "print(x_train_noisy)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVVD9lNUebln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/1260_mercator/mercator_total_noisy1.npy',x_train_noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C205la_quPs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load('/content/drive/My Drive/1260_mercator/mercator_total.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6iGztIrdr9S",
        "colab_type": "code",
        "outputId": "c808de5c-e5bd-4243-8a0c-fa4ced1fbb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        }
      },
      "source": [
        "plt.imshow(x_train[120],vmin=-1,vmax=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f77dcff5e80>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAACVCAYAAABB56G6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4BC/S/XOV81LdmFAwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDNOAoGX3J3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddf494e9-7551-4560-9356-97d1e9e02e35"
      },
      "source": [
        "print(x_train[1].shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(21, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXPYKkoMwn03",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adam_optimizer():\n",
        "  return Adam(lr=0.0002, beta_1=0.5)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TKrvOwUe9Wz",
        "colab_type": "code",
        "outputId": "2d826e00-d311-4770-9b52-776ba94dc954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "# input matriz (21,60)\n",
        "# output array 128\n",
        "def create_encoder():\n",
        "  \n",
        "    encoder=Sequential()\n",
        "\n",
        "    encoder.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),input_shape=(21,60,1), activation='tanh',name='e_conv2d_1'))\n",
        "    encoder.add(BatchNormalization())\n",
        "    #encoder.add(LeakyReLU(alpha=0.2))\n",
        "    encoder.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),name='e_maxpool_1'))\n",
        "    \n",
        "    encoder.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), activation='tanh',name='e_conv2d_2'))\n",
        "    encoder.add(BatchNormalization())\n",
        "    #encoder.add(LeakyReLU(alpha=0.2))\n",
        "    encoder.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1),name='e_maxpool_2'))\n",
        "    \n",
        "    encoder.add(Flatten())\n",
        "    encoder.add(Dense(units=128, activation='tanh'))\n",
        "    encoder.add(BatchNormalization())\n",
        "    \n",
        "    encoder.compile(loss='mse', optimizer=adam_optimizer())\n",
        "    encoder.name='encoder'\n",
        "    return encoder\n",
        "encoder = create_encoder()\n",
        "encoder.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "e_conv2d_1 (Conv2D)          (None, 17, 56, 32)        832       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 17, 56, 32)        128       \n",
            "_________________________________________________________________\n",
            "e_maxpool_1 (MaxPooling2D)   (None, 16, 55, 32)        0         \n",
            "_________________________________________________________________\n",
            "e_conv2d_2 (Conv2D)          (None, 12, 51, 32)        25632     \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 12, 51, 32)        128       \n",
            "_________________________________________________________________\n",
            "e_maxpool_2 (MaxPooling2D)   (None, 11, 50, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 17600)             0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 128)               2252928   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 128)               512       \n",
            "=================================================================\n",
            "Total params: 2,280,160\n",
            "Trainable params: 2,279,776\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGM3jxgy28pV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "5e044084-7a32-4cb8-daf7-bb3b5d6d847d"
      },
      "source": [
        "# input array 128\n",
        "# output matriz (21,60)\n",
        "def create_decoder():\n",
        "  decoder=Sequential()\n",
        "\n",
        "  decoder.add(Dense(128 * 5 * 3, input_dim=128, name='dense'))\n",
        "  decoder.add(Reshape((3, 5, 128), name='reshape'))\n",
        "\n",
        "  decoder.add(Conv2DTranspose(64, (5,5), strides=(7,3), padding='same', name='conv2dt_1'))\n",
        "  decoder.add(Conv2DTranspose(1, (5,5), strides=(1,4), padding='same', name='conv2dt_2'))\n",
        "\n",
        "  decoder.compile(loss='mse', optimizer=adam_optimizer())\n",
        "  decoder.name='decoder'\n",
        "  return decoder\n",
        "decoder = create_decoder()\n",
        "decoder.summary()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 1920)              247680    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 3, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2dt_1 (Conv2DTranspose)  (None, 21, 15, 64)        204864    \n",
            "_________________________________________________________________\n",
            "conv2dt_2 (Conv2DTranspose)  (None, 21, 60, 1)         1601      \n",
            "=================================================================\n",
            "Total params: 454,145\n",
            "Trainable params: 454,145\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nlevBVG661LH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d5f6df42-a294-469f-cfce-8b5f4aff27e1"
      },
      "source": [
        "def autoencoder(encoder,decoder):\n",
        "  autoencoder_input = Input(shape=(21,60,1))\n",
        "  x = encoder(autoencoder_input)\n",
        "  autoencoder_output=decoder(x)\n",
        "  autoencoder = Model(inputs=[autoencoder_input], outputs=autoencoder_output)\n",
        "  autoencoder.compile(loss='mse', optimizer='adam')\n",
        "  autoencoder.name='autoencoder'\n",
        "  return autoencoder\n",
        "\n",
        "autoencoder=autoencoder(encoder,decoder)\n",
        "autoencoder.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 21, 60, 1)         0         \n",
            "_________________________________________________________________\n",
            "encoder (Sequential)         (None, 128)               2280160   \n",
            "_________________________________________________________________\n",
            "decoder (Sequential)         (None, 21, 60, 1)         454145    \n",
            "=================================================================\n",
            "Total params: 2,734,305\n",
            "Trainable params: 2,733,921\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Hydc9p8fkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(x_train, y_train, epochs, batch_size, sample_intervals):\n",
        "  for epoch in range(epochs):\n",
        "    #entrenar el decoder\n",
        "    latente = encoder.predict(x_train)\n",
        "    decoder.fit(latente,y_train,batch_size, epochs=1)\n",
        "    #entrenar el encoder\n",
        "    encoder.fit(x_train,latente,batch_size,epochs=1)\n",
        "    #guardar modelos y dibujar cada 20 epocas\n",
        "    encoder.save(\"encoder_prueba.h5\")\n",
        "    decoder.save(\"decoder_prueba.h5\")\n",
        "    print(\"Saved model to disk\")\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yotdxAh78EKJ",
        "colab_type": "code",
        "outputId": "23f5f8b3-71a4-41da-d52a-69a53ab76268",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,epochs=100,batch_size=128,shuffle=True,validation_data=(x_test_noisy, x_test),)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9c3ac70c63d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_noisy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected input_2 to have 4 dimensions, but got array with shape (60000, 28, 28)"
          ]
        }
      ]
    }
  ]
}